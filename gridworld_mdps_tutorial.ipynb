{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorayala/AI_Machine_Learning_2024/blob/main/gridworld_mdps_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a06b683c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fbbd87ff85c642ac83f5e5f776093fa",
          "grade": false,
          "grade_id": "cell-30e896a570f1ceb5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a06b683c"
      },
      "source": [
        "![Banner](Banner.jpg)\n",
        "\n",
        "# Definición de un MDP para Gridworld\n",
        "\n",
        "En este tutorial vamos a definir un ambiente de prueba comúnmente utilizado en el aprendizaje por refuerzo; el ambiente de Gridworld. Vamos a definir el ambiente de Gridworld como un Markov Decision Process (MDP) para luego establecer solución con los diferentes métodos basados en modelos y libres de modelos.\n",
        "Gridworld es un ambiente clásico de prueba dentro del aprendizaje por refuerzo. Durante este tutorial definiremos el modelo básico del ambiente, que extenderemos incrementalmente de acuerdo con las necesidades de los algoritmos específicos de solución que desarrollaremos a lo largo del curso.\n",
        "\n",
        "Los ambientes de aprendizaje por refuerzo se pueden definir en dos (ambiente, agente) o tres (ambiente, agente, aprendizaje) módulos. Por simplicidad, dentro de nuestra implementación de Gridworld (e implementaciones posteriores) utilizaremos dos módulos. Sin embargo, cabe notar que una implementación utilizando tres módulos ofrece una mejor división de las características y por lo tanto una implementación más fácil de mantener y modificar.\n",
        "\n",
        "Para cada uno de los módulos a continuación daremos una clase principal de código sobre la cual se deben hacer todas las modificaciones. Cada una de las funciones a implementar se presentarán progresivamente. Para cada una de las funciones a implementar se dará un conjunto (mínimo) de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMVqsCSEkgE4",
        "outputId": "3df59107-e995-4ecd-9fe5-d78723a15d6b"
      },
      "id": "pMVqsCSEkgE4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0769e1b8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "833a42c92da63dad82a57185a7101303",
          "grade": false,
          "grade_id": "cell-7def3dbbdb35eb5a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0769e1b8"
      },
      "source": [
        "## Ambiente 🌎\n",
        "\n",
        "El ambiente de Gridworld se define como una cuadricula de `nxm`. El ambiente tiene obstáculos, es decir casillas por las cuales no puede pasar el agente. Al chocar con un obstáculo, el agente termina en la misma casilla en la que estaba. Un comportamiento similar se observa cuando el agente trata de salir de los bordes del ambiente. Además, el ambiente tiene una casilla de inicio definida, y algunas casillas de salida (determinadas por la recompensa asociada a ellas). Un ejemplo del ambiente para el caso `3x4` se muestra a continuación.\n",
        "\n",
        "![gridworld.png](gridworld.png)\n",
        "\n",
        "En este ejemplo del ambiente la casilla de inicio es la casilla inferior izquierda y tiene como objetivo llegar a la casilla de salida con recompensa 1. La otra casilla de salida tiene recompensa -1.\n",
        "\n",
        "\n",
        "#### ¿Cómo podemos codificar el ambiente?\n",
        "\n",
        "La definición del ambiente de Gridworld esta definida por:\n",
        "1. Una cuadrícula rectangular (`grid`), con dimensiones `(n,m)` dadas por parámetro, donde la casilla superior izquierda esta en la posición (0,0). Definiremos las casillas por las que puede pasar el agente como espacios en blanco y las casillas por las que no puede pasar el agente con un `'#'`.\n",
        "2. Las recompensas de cada casilla de la cuadrícula estan definidas dentro de la definición de `grid`.\n",
        "    - +1 para la casilla objetivo\n",
        "    - -1 para las casillas de trampa\n",
        "3. Un atributo con el estado actual (`state`) en el que se encuentra el agente. Por defecto este estado será la posición marcada como `S`.\n",
        "\n",
        "Un ejemplo de una cuadrícula de 3x4, como se mostró anteriormente, sería así:\n",
        "\n",
        " ```python  \n",
        "    board = [[' ', ' ', ' ',  +1],\n",
        "            [' ', '#', ' ',  -1],\n",
        "             ['S', ' ', ' ', ' ']]\n",
        "```\n",
        "\n",
        "La definición del ambiente un ejemplo de recompensas se vería así:\n",
        "\n",
        "```python\n",
        "    def __init__(self, board):\n",
        "        # layout\n",
        "        self.grid = copy_elements_from_the_board\n",
        "```\n",
        "\n",
        "\n",
        "#### 1. Estructura del ambiente\n",
        "\n",
        "Defina la clase `Gridworld`, que recibe una cuadrícula con la descripción del tablero `board`, definidos como en el ejemplo. La información codificada en la cuadrícula será almacenada en el atributo `grid` del ambiente (este atributo corresponde al mdp donde se almacena la información del ambiente, la función de transición y las recompensas). Adicionalmente, para facilitar el uso del mdp, definimos los atributos para guardar la información de la cuadrícula; las filas (`nrows`) y columnas (`ncols`). esta información se da por parámetro (`dimensions`), al instanciar la clase, como una tupla con los valores respectivos. Adicionalmente la clase debe tener los atributos `initial_state` y `state` que corresponden al estado inicial y el estado actual del agente en el ambiente, respectivamente. Estos atributos se guardan como tuplas.\n",
        "\n",
        "Finalmente, el atributo `grid` se debe codificar de tal forma que las casillas prohibidas (marcadas como `'#'`) no deben tener ningún valor asignado (su valor debe ser `None`), las casillas en blanco deben tener valor `0`, y las casillas con recompensas asociadas deben tener el valor de la recompensa como su valor. Note que con esta codificación de `grid`, y teniendo en cuenta que las acciones son determinísticas, estamos codificando directamente las recompensas del ambiente. Si este no fuera el caso, sería necesario definir un nuevo atributo `rewards`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c83e984",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3dbebfa0c0d4d46d7fb5d6df9107eef",
          "grade": false,
          "grade_id": "cell-11f1d5794939d3dd",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2c83e984"
      },
      "outputs": [],
      "source": [
        "#Definición del ambiente de gridworld\n",
        "\n",
        "#Librerias de gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#Definición de la clase principal\n",
        "class Gridworld:\n",
        "    def __init__(self, board, dimensions):\n",
        "        # your code here\n",
        "        self.grid = [[None if cell == '#' else -1 if cell == '-1' else 1 if cell == '+1' else cell\n",
        "                     for cell in row] for row in board]\n",
        "        self.nrows, self.ncols = dimensions  # Dimensiones de la cuadrícula\n",
        "        self.initial_state = self.find_start()  # Encuentra la posición de inicio (marcada como S)\n",
        "        self.state = self.initial_state  # Establece el estado inicial del agente\n",
        "        self.board = board\n",
        "        #raise NotImplementedError\n",
        "\n",
        "\n",
        "    def get_current_state(self):\n",
        "        # your code here\n",
        "        return self.state\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    def get_possible_actions(self, state):\n",
        "        \"\"\"\n",
        "        Given a state, returns the possible actions that can be taken from that state.\n",
        "        \"\"\"\n",
        "        # If the state is a reward state or a forbidden state, then no actions can be taken.\n",
        "        if self.board[state[0]][state[1]] in ['-1', '+1', '#']: # Added '#' to the condition\n",
        "            if self.board[state[0]][state[1]] in ['-1', '+1']:\n",
        "                return ['exit']\n",
        "            else:\n",
        "                return []  # Return empty list for forbidden states\n",
        "        else:\n",
        "            # Otherwise, the possible actions are up, down, left, and right.\n",
        "            return ['up', 'down', 'left', 'right']\n",
        "\n",
        "\n",
        "    def do_action(self, action):\n",
        "        x, y = self.state\n",
        "        if action == 'up' and x > 0 and self.grid[x - 1][y] is not None:  # Check for wall\n",
        "            self.state = (x - 1, y)\n",
        "        elif action == 'down' and x < self.nrows - 1 and self.grid[x + 1][y] is not None:  # Check for wall\n",
        "            self.state = (x + 1, y)\n",
        "        elif action == 'left' and y > 0 and self.grid[x][y - 1] is not None:  # Check for wall\n",
        "            self.state = (x, y - 1)\n",
        "        elif action == 'right' and y < self.ncols - 1 and self.grid[x][y + 1] is not None:  # Check for wall\n",
        "            self.state = (x, y + 1)\n",
        "\n",
        "        return self.grid[self.state[0]][self.state[1]], self.state\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        # your code here\n",
        "        self.state = self.initial_state\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # your code here\n",
        "        x, y = self.state\n",
        "        return self.grid[x][y] in [1, -1]\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    #Funciones auxiliares\n",
        "    def get_action_index(self, action):\n",
        "        actions = ['up', 'right', 'down', 'left']\n",
        "        index = 0\n",
        "        for a in actions:\n",
        "            if action == a:\n",
        "                return index\n",
        "            index += 1\n",
        "\n",
        "\n",
        "    def find_start(self):\n",
        "        for i in range(self.nrows):\n",
        "            for j in range(self.ncols):\n",
        "                if self.grid[i][j] == 'S':  # Busca la casilla de inicio\n",
        "                    self.grid[i][j] = 0 # Actualizamos el valor de la celda de 'S' a 0\n",
        "                    return (i, j)\n",
        "    def plot(self):\n",
        "        fig1 = plt.figure(figsize=(10, 10))\n",
        "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
        "\n",
        "        # Lineas\n",
        "        for i in range(0, len(self.grid)+1):\n",
        "            ax1.axhline(i , linewidth=2, color=\"#2D2D33\")\n",
        "            ax1.axvline(i , linewidth=2, color=\"#2D2D33\")\n",
        "\n",
        "        # Amarillo - estado inicial\n",
        "        (i,j)  = self.initial_state\n",
        "        ax1.add_patch(patches.Rectangle((j, self.nrows - i -1), 1, 1, facecolor = \"#F6D924\"))\n",
        "        for j in range(len(self.grid[0])):\n",
        "            for i in range(len(self.grid)):\n",
        "                if self.grid[i][j] == 1: # verde\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#68FF33\"))\n",
        "                if self.grid[i][j] == None: # gris\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#6c7780\"))\n",
        "                if self.grid[i][j] == -1: # rojo\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#cc0000\"))\n",
        "        plt.scatter(self.state[1] + 0.5, self.nrows - self.state[0] - 1 +0.5, s = 100, color = \"black\", marker = \"o\", facecolor = \"blue\", edgecolors = \"blue\", zorder = 10)\n",
        "        for i in range(len(self.grid)):\n",
        "            for j in range(len(self.grid[0])):\n",
        "                if self.grid[i][j] == None:\n",
        "                    ax1.text(self.ncols-j-1, self.nrows-i-1, \"\", ha='center', va='center')\n",
        "                else:\n",
        "                    ax1.text(j+0.5, self.nrows-i-1+0.5, self.grid[i][j], ha='center', va='center')\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ca18e5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5b66ef3329c55eec92d22fd33bb252df",
          "grade": true,
          "grade_id": "cell-d02ebef01da3ead9",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e1ca18e5"
      },
      "outputs": [],
      "source": [
        "#Pruebas estructura del ambiente\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.nrows\n",
        "except:\n",
        "    print(\"El atributo nrows no está definido\")\n",
        "try:\n",
        "    grid.ncols\n",
        "except:\n",
        "    print(\"El atributo ncols no está definido\")\n",
        "try:\n",
        "    grid.initial_state\n",
        "except:\n",
        "    print(\"El atributo initial_state no está definido\")\n",
        "\n",
        "try:\n",
        "    grid.state\n",
        "except:\n",
        "    print(\"El atributo state no está definido\")\n",
        "\n",
        "try:\n",
        "    grid.grid\n",
        "except:\n",
        "    print(\"El atributo grid no está definido\")\n",
        "\n",
        "assert grid.ncols == 3, \"El valor de las columnas debe ser el dado por parámetro en el atributo dimensions\"\n",
        "assert grid.nrows == 3, \"El valor de las columnas debe ser el dado por parámetro en el atributo dimensions\"\n",
        "assert grid.grid[1][1] == None, \"El valor de las casillas sobre las que no puede pasar el agente debe ser None\"\n",
        "assert grid.grid[0][2] == -1, \"El valor de las casillas con recompensa debe ser el valor numérico (tipo int)\"\n",
        "assert grid.initial_state == (1,0), \"La posición inicial del agente debe ser la definida en el estado S de la cuadrícula dada\"\n",
        "assert grid.initial_state == grid.state, \"La posición del agente debe ser igual a su posición inicial si ningún paso se ha dado\"\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cdc76dc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f9966fc40d95a55467d6d8035edfc543",
          "grade": false,
          "grade_id": "cell-449b5d30df6612e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8cdc76dc"
      },
      "source": [
        "#### 2. Movimientos del agente\n",
        "\n",
        "Defina la función `do_action` que ejecuta la acción tomada por el agente dentro de la cuadrícula. Esta función recibe como parámetro la acción a ejecutar y retorna el valor de la casilla de llegada de la acción y el estado de llegada de la acción (como una tupla). Note que los movimientos fuera del tablero o las casillas prohibidas no deberían tener ningún efecto en la posición del agente (el agente se debe mantener en la misma posición de partida).\n",
        "\n",
        "En esta versión de gridworld vamos a trabajar con acciones determinísticas, es decir el movimiento deseado del agente (`up`,`right`,`down`,`left`) siempre resultara en el estado esperado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9889cd50",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "50492d938ddd4742f9e5e607beb7043f",
          "grade": true,
          "grade_id": "cell-4c2ec1213aac0a9d",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9889cd50"
      },
      "outputs": [],
      "source": [
        "#Pruebas de movimiento\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.do_action\n",
        "except:\n",
        "    print(\"La función do_action no está definida\")\n",
        "\n",
        "val, state = grid.do_action('up')\n",
        "assert state == (0,0), f\"El movimiento hacia arriba no esta modificando correctamente al agente, se movió a {state} y debería ser (0,0)\"\n",
        "val, state = grid.do_action('right')\n",
        "assert state == (0,1), f\"El movimiento hacia la derecha no esta modificando correctamente al agente, se movió a {state} y debería ser (0,1)\"\n",
        "val, state = grid.do_action('right')\n",
        "assert val == -1, f\"El valor de las casillas no se esta retornando correctamente\"\n",
        "val, state = grid.do_action('down')\n",
        "assert state == (1,2), f\"El movimiento hacia la derecha no esta modificando correctamente al agente, se movió a {state} y debería ser (1,2)\"\n",
        "val, state = grid.do_action('left')\n",
        "assert state == (1,2), f\"El movimiento hacia la derecha no esta modificando correctamente al agente, se movió a {state} y debería ser (1,2)\"\n",
        "\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf0a92c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1eb73f2b6fe47f3dd5e95d11c93f5863",
          "grade": false,
          "grade_id": "cell-cef0ee02db9824ce",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fbf0a92c"
      },
      "source": [
        "#### 3. Estado actual\n",
        "\n",
        "Defina la función `get_current_state` que retorna el estado actual del agente (la casilla donde se encuentra el agente). Esta función no recibe ningún parámetro y retorna el estado actual como una tupla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4f9174",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ea0575665561be4687b2ffddcf5e4ef6",
          "grade": true,
          "grade_id": "cell-44709443d150a086",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "be4f9174"
      },
      "outputs": [],
      "source": [
        "#Pruebas estado actual\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.get_current_state\n",
        "except:\n",
        "    print(\"La función get_current_state no está definida\")\n",
        "\n",
        "assert grid.get_current_state() == (1,0), \"La posición del agente debe ser la posición inicial si no se realiza ningún movimeinto\"\n",
        "grid.do_action('up')\n",
        "assert grid.get_current_state() == (0,0), f\"La posición del agente no se esta modificando correctamente, recibió {grid.get_current_state()} cuando debería ser (0,0), revise los movimientos\"\n",
        "grid.state = (1,0)\n",
        "grid.do_action('right')\n",
        "assert grid.get_current_state() == (1,0), \"El agente no se mantiene en la misma posición cuando trata de moverse a la casilla prohibida\"\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817babdf",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a87b8280f7eaf836d1684523f69c4048",
          "grade": false,
          "grade_id": "cell-a2363364694eb96e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "817babdf"
      },
      "source": [
        "#### 4. Obtener las acciones\n",
        "\n",
        "Defina la función `get_possible_actions` que recibe el estado actual del agente por parámetro y retorna una lista de las acciones válidas para el estado dado.\n",
        "\n",
        "Tenga en cuenta que en esta versión de Gridworld, todas las acciones (i.e., los movimientos en las cuatro direcciones) son posibles para el agente en cada una de las casillas regulares de la cuadrícula. Las casillas de salida tienen única acción posible `'exit'` y las casillas prohibidas no tienen ningúna acción asociada (una lista vacía de acciones)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18986d8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb58e73cdec6f0a37fc1e8bb6eabc7a3",
          "grade": true,
          "grade_id": "cell-b829a305b1615d60",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c18986d8"
      },
      "outputs": [],
      "source": [
        "#Pruebas de acciones posibles\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.get_possible_actions\n",
        "except:\n",
        "    print(\"La función get_possible_actions no está definida\")\n",
        "\n",
        "a1 = grid.get_possible_actions(grid.state)\n",
        "a2 = grid.get_possible_actions((1,0))\n",
        "a3 = grid.get_possible_actions((1,2))\n",
        "a4 = grid.get_possible_actions((0,1))\n",
        "a5 = grid.get_possible_actions((2,1))\n",
        "ap = grid.get_possible_actions((1,1))\n",
        "ar1 = grid.get_possible_actions((0,2))\n",
        "ar2 = grid.get_possible_actions((2,2))\n",
        "assert ap == [], \"Las acciones para las casillas prohibidas deben estar vacias\"\n",
        "assert a1 == a2 == a4 == a5, f\"Todas las casillas regulares deben tener el mismo conjunto de acciones {['up', 'right', 'down', 'left']}\"\n",
        "assert ar1 == ar2, f\"Todas las casillas de salida deben tener el mismo conjunto de acciones {['exit']}\"\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffa06d65",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a939f732e5e93ebcde4c50f067062c07",
          "grade": false,
          "grade_id": "cell-d76f87aa491607d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ffa06d65"
      },
      "source": [
        "\n",
        "#### 5. Reinicializar el ambiente\n",
        "\n",
        "Defina la función `reset` que no recibe parámetros ni retorna ningún valor. El efecto de esta función es restablecer el ambiente a su estado inicial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599a72a4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "894e2c6e12d970ea98fa5f872bba2b6c",
          "grade": true,
          "grade_id": "cell-365f971ddb690a05",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "599a72a4"
      },
      "outputs": [],
      "source": [
        "#Pruebas de reset\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.reset\n",
        "except:\n",
        "    print(\"La función reset no está definida\")\n",
        "\n",
        "grid.state = (2,2)\n",
        "grid.reset()\n",
        "assert grid.get_current_state() == grid.initial_state, f\"No se esta retornando al estado inicial. {grid.get_current_state()} y no {grid.initial_state}\"\n",
        "grid.state = (1,1)\n",
        "grid.reset()\n",
        "assert grid.get_current_state() == grid.initial_state, f\"No se esta retornando al estado inicial. {grid.get_current_state()} y no {grid.initial_state}\"\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a9d4f38",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0a85ca59c65b35130dd2eb2a1e8dff78",
          "grade": false,
          "grade_id": "cell-5761e4534eaa648f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0a9d4f38"
      },
      "source": [
        "\n",
        "#### 6. Estados terminales\n",
        "\n",
        "Defina la función `is_terminal` que determina si el agente está en un estado final o no. En nuestro caso los estados finales o los estados de salida estarán determinados por las casillas con recompensa 1 o -1.\n",
        "Esta función no recibe parámetros y retorna un booleano determinando si el agente está en un estado final o no."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956ac29f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29373fa35b0635bde967a6efab1dc100",
          "grade": true,
          "grade_id": "cell-b5125fef529b7d6a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "956ac29f"
      },
      "outputs": [],
      "source": [
        "#Pruebas terminación\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.is_terminal\n",
        "except:\n",
        "    print(\"La función is_terminal no está definida\")\n",
        "\n",
        "grid.state = (2,2)\n",
        "assert grid.is_terminal() == True, f\"No se identifican correctamente los estados de salida como finales\"\n",
        "grid.state = (0,2)\n",
        "assert grid.is_terminal() == True, f\"No se identifican correctamente los estados de salida como finales\"\n",
        "\n",
        "for i in range(grid.nrows):\n",
        "    for j in range(grid.ncols):\n",
        "        grid.state = (i,j)\n",
        "        if (i,j) == (0,2) or (i,j) == (2,2):\n",
        "            assert grid.is_terminal() == True, f\"No se identifican correctamente los estados de salida como finales\"\n",
        "        else:\n",
        "            assert grid.is_terminal() == False, f\"La casilla {(i,j)} se estan identificando como estado final\"\n",
        "\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccb3db9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cb94b110cc88e9c8b69cad807ccfc213",
          "grade": false,
          "grade_id": "cell-7140c70618ce81ec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2ccb3db9"
      },
      "source": [
        "## Preguntas de reflexión\n",
        "\n",
        "Considere las siguientes situaciones y piense cual debería ser el resultado del MDP.\n",
        "\n",
        "1. Plantee el problema de MDP para cada una de las casillas. Especifique el estado de inicio, las transiciones y su probabilidad. Para cada acción suponga una probabilidad de éxito de 0.25 (el 0.75 restante se resuelve uniformemente entre las acciones restantes).\n",
        "¿Cómo serían las recompensas esperadas para cada estado?\n",
        "\n",
        "2. Bajo la definción del problema anterior, suponga que ahora cada acción tiene una probabilidad de éxito de 60%, con probabilidad de 30% que se ejecutará la sigiente acción (en dirección de las manesillas del reloj) y con probabilidad de 10% que no se ejecute ninguna acción (el agente se queda quieto). Bajo estas condiciones, ¿Cómo serían las recompensas esperadas para cada estado?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}